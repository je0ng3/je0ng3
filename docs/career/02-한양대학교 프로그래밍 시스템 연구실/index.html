<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8" />
    <title>JUNGEUN PARK</title>
    <link
        rel="stylesheet"
        href="../../static/css/styles.css"
    />
    </head>

    <body>
        <header>
            <div class="header-content">
                <a href="/" class="logo">JE</a>
            </div>
        </header>
            
        <main>
            <h1>한양대학교 프로그래밍 시스템 연구실</h1>
            <h2>Summary</h2>
            <p><strong>연구실 인턴 | LLM을 사용한 코드 자동 생성 프로그램 구현 및 모델 성능 검사</strong> (2024.03.02 - 2024.08.30 ) 
                | Python, Hugging Face, PyTorch, TensorFlow, Transformers</p>
            <ul>
                <li>Python 코드 생성을 위한 미완성 코드 샘플을 보완하고, 동일한 구조를 C++ 코드 생성으로 확장</li>
                <li>코드 생성 과정을 토큰 단위로 출력하도록 수정하여 생성 실패 원인 분석 및 새로운 종료 조건 정의</li>
                <li>Kaggle에서 적절한 데이터셋을 찾아 형식에 맞게 전처리하고 테스트에 활용</li>
            </ul>
            <br>

            <h2>Tasks</h2>
            <ul>
                <li>Hugging Face 기반 LLM을 활용한 자연어 → 코드 변환 시스템 설계 및 구현</li>
                <li>Python 코드 자동 생성 기능 보완 및 C++ 코드 생성 기능 추가</li>
                <li>토큰 단위 출력 설정을 통해 생성 중단 원인 분석 및 종료 조건 직접 정의</li>
                <li>Kaggle에서 수집한 데이터셋을 전처리하여 테스트</li>
                <li>생성 코드의 컴파일 결과를 기반으로 모델의 정확도 평가 </li>
            </ul>

            <h2>Skills</h2>
            <table>
                <tbody>
                    <tr>
                        <td>Languages</td>
                        <td><code>Python</code></td>
                    </tr>
                    <tr>
                        <td>Frameworks</td>
                        <td><code>Hugging Face, Transformers, PyTorch, ANTLR</code></td>
                    <tr>
                        <td>Benchmark</td>
                        <td><code>THUDM/humaneval-x</code></td>
                    </tr>
                    <tr>
                        <td>Model</td>
                        <td><code>DDIDU/ETRI_CodeLLaMA_7B_CPP, meta-llama/Meta-Llama-3-8B</code></td>
                    </tr>
                </tbody>
            </table>

            <h2>Reflection</h2>
            <p>
                LLM이 코드를 생성하는 과정을 토큰 단위로 살펴보며, 코드가 제대로 생성되지 않거나 컴파일 에러가 발생하는 경우의 원인을 분석하는 과정이 좋았습니다.
                코드를 단계별로 나눠서 확인하고, 렉싱이나 파싱 오류를 하나씩 잡아가며 구현하는 과정이 마치 디버깅하듯 느껴져서 흥미로웠습니다. <br>
                다양한 데이터를 테스트하면서 논리 오류만을 잡아내는 것이 목표였는데, 평가 방식이 컴파일 중심이어서 런타임 오류까지 잡아버렸는데, 이를 해결하지 못하고 연구실 활동이 마무리 되어 아쉬웠습니다.
                이번 프로젝트에서는 성능 평가를 중심으로 구현했지만, 다음에는 코드 생성의 정확도를 높이기 위한, 문제를 해결하고 생산성을 높기기 위한 일까지 해보고 싶습니다.
            </p>
            
        </main>


        <footer>&copy; 2025 Jungeun Park. All rights reserved.</footer>        
    </body>
</html>